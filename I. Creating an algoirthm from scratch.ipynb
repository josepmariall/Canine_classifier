{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of I. Creating an algoirthm from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "J5oKytTirOMn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# I. Creating an algoirthm from scratch\n",
        "\n",
        "In this notebook, I create an algoirthm from scratch to classify different dog breeds \n",
        "\n",
        "Initially, we shall start with: \n",
        "\n",
        "  0. Importing libraries\n",
        "  1. Importing datasets\n",
        "  2. Create a CNN to Classify  Canine Breeds from scratch\n",
        "  \n",
        "  2.1 Evaluate algorithm created. \n",
        "  \n",
        "  3. Opportunity for improvement\n",
        "  \n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "65sODGDRPN2i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 0.Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "KlYKjHOjl534",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We start by importing libraries\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "import ast\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-VMyUSeedEK",
        "colab_type": "code",
        "outputId": "f7a39620-546e-4d8a-9108-c40c9ac64470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5SScQPdFfyY7",
        "colab_type": "code",
        "outputId": "65336351-fca5-4d13-a4b1-c56b66906167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m10HG5BUekAS",
        "colab_type": "code",
        "outputId": "29a27bd8-f393-4ac0-9c63-9780c4f5c7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Fx_Cp05b7zH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.Import datasets\n",
        "The following datasets are imported:\n",
        "- Dog images\n",
        "- Humans\n",
        "- Pre-trained face detector"
      ]
    },
    {
      "metadata": {
        "id": "lqAi-NfNrICo",
        "colab_type": "code",
        "outputId": "0e6a49c1-5d56-446a-8c3c-aa20ac19abef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Downloading the dog and human dataset\n",
        "from IPython.display import clear_output\n",
        "!wget -cq -O dogImages.zip https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "!wget -cq -O lfw.tgz http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "clear_output()  \n",
        "print(\"Downloaded Successfully\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b6pQ6fyuroT-",
        "colab_type": "code",
        "outputId": "eed0d186-60ef-44d5-dac9-e7808db755e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Extractting the datasets\n",
        "!unzip -n dogImages.zip\n",
        "!tar -xvzf lfw.tgz\n",
        "clear_output()\n",
        "print(\"Extracted Successfully\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ObcfKzwVron6",
        "colab_type": "code",
        "outputId": "38459893-88f2-4292-f3e7-443db6f584ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Find out the number of images for each category\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# load filenames for human and dog images\n",
        "human_files = np.array(glob(\"lfw/*/*\"))\n",
        "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print('There are %d total human images.' % len(human_files))\n",
        "print('There are %d total dog images.' % len(dog_files))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 13233 total human images.\n",
            "There are 8351 total dog images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TTTdoq82vkhl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.Create Classifier from Scratch\n",
        "\n",
        "Before doing so, we are going to run some code in order to help us :\n",
        "\n",
        "* Run faster the code using GPU if available\n",
        "\n",
        "*  Prepare images for Classification\n",
        "\n",
        "*  Specify data directories"
      ]
    },
    {
      "metadata": {
        "id": "YB2hhNBExlrE",
        "colab_type": "code",
        "outputId": "edd2b8ff-186c-4825-a52c-569a3c046dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Is GPU available: ', 'Yes' if torch.cuda.is_available() else 'No')\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is GPU available:  Yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D3rqLZTGCwYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Prepare images for classification"
      ]
    },
    {
      "metadata": {
        "id": "LsmcNe5Zfa0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code will help us when dealing with images to be used in different classification models#\n",
        "#from PIL import Image\n",
        "#import torchvision.transforms as transforms\n",
        "#from torch.autograd import Variable\n",
        "\n",
        "def process_image_to_tensor(image):\n",
        "\n",
        "    # define transforms for the training data and testing data\n",
        "    prediction_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                          transforms.CenterCrop(224),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "    \n",
        "    img_pil = Image.open( image ).convert('RGB')\n",
        "    img_tensor = prediction_transforms( img_pil )[:3,:,:].unsqueeze(0)\n",
        "    \n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "# helper function for un-normalizing an image  \n",
        "# and converting it from a Tensor image to a NumPy image for display\n",
        "def image_convert(tensor):\n",
        "    \"\"\" This is to display a tensor as an image. \"\"\"\n",
        "    \n",
        "    image = tensor.to(\"cpu\").clone().detach()\n",
        "    image = image.numpy().squeeze()\n",
        "    image = image.transpose(1,2,0)\n",
        "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
        "    image = image.clip(0, 1)\n",
        "\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmhg2oF_C4rL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Specify the directories"
      ]
    },
    {
      "metadata": {
        "id": "2gNRjiS6xYyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specify directories\n",
        "data_dir = 'dogImages'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bi3Y8giO1hjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "### TODO: Write data loaders for training, validation, and test sets\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "# Batch size\n",
        "batch_size = 20\n",
        "# For faster computation, setting num_workers\n",
        "num_workers = 0\n",
        "\n",
        "# Transforms for the training, validation, and testing sets\n",
        "data_transforms = {\n",
        "    'train'      : transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])]),\n",
        "\n",
        "    'valid'      : transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])]),\n",
        "    'test'       : transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "}\n",
        "\n",
        "# Loading the datasets with ImageFolder\n",
        "image_datasets = {\n",
        "    'train'  : datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
        "    'valid'  : datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n",
        "    'test'   : datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
        "}\n",
        "\n",
        "# Using the image datasets and the trainforms to define dataloaders\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(image_datasets['train'], batch_size = 32, shuffle=True, num_workers = num_workers),\n",
        "    'valid' : torch.utils.data.DataLoader(image_datasets['valid'], batch_size = 16),\n",
        "    'test'  : torch.utils.data.DataLoader(image_datasets['test'], batch_size = 16)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fak9s1qnzk7S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Define Data Architecture for scratch model "
      ]
    },
    {
      "metadata": {
        "id": "S_1tch2UxLgW",
        "colab_type": "code",
        "outputId": "2bfe1837-f490-4d2e-aa32-c384431dda12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "# Model Architecture\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "            \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 224*224*3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 112*112*32 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 56*56*64 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        \n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (64 * 28 * 28 -> 500)\n",
        "        self.fc1 = nn.Linear(64*28*28, 500)\n",
        "        # linear layer (500 -> 133)\n",
        "        self.fc2 = nn.Linear(500, 133)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()\n",
        "\n",
        "print(model_scratch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=50176, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=133, bias=True)\n",
            "  (dropout): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWFePh4806uX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Define Loss Function and Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "z5P0BH7nxC98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specifiy Loss Function and Optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jn06Qiae1Coa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Train and validate the model"
      ]
    },
    {
      "metadata": {
        "id": "qZxpO6ZpxDQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part helps building a robust training to deal with truncated images\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    print(\"start training for {} epochs ...\".format(n_epochs))\n",
        "\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    # exist save-file, load save file\n",
        "    if os.path.exists(save_path):\n",
        "        print(\"load previous saved model ...\")\n",
        "        model.load_state_dict(torch.load(save_path))\n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            \n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "     \n",
        "        # print training/validation statistics \n",
        "        print('\\n-----------------------------------------------------------------------------\\nEpoch: {} \\nTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss has decreased from ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NmE7GYXPxDbJ",
        "colab_type": "code",
        "outputId": "65e142bf-d582-4e1d-886d-8b93dd273558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "loaders_scratch = loaders\n",
        "\n",
        "model_scratch = train(5, loaders_scratch, model_scratch, optimizer_scratch, \n",
        "                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training for 5 epochs ...\n",
            "load previous saved model ...\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "Epoch: 1 \n",
            "Training Loss: 4.014856 \tValidation Loss: 3.895001\n",
            "Validation loss has decreased from (inf --> 3.895001).  Saving model ...\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "Epoch: 2 \n",
            "Training Loss: 4.004414 \tValidation Loss: 3.926379\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "Epoch: 3 \n",
            "Training Loss: 3.975496 \tValidation Loss: 3.936420\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "Epoch: 4 \n",
            "Training Loss: 3.960790 \tValidation Loss: 3.941092\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "Epoch: 5 \n",
            "Training Loss: 3.944167 \tValidation Loss: 3.911684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7G8RJ-LXIuQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model has been trained for 22 epochs through  different rounds. "
      ]
    },
    {
      "metadata": {
        "id": "jg3RlSEmI3Bd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.6 Test the model"
      ]
    },
    {
      "metadata": {
        "id": "V1AEanl-I1xx",
        "colab_type": "code",
        "outputId": "32ae49f9-862b-4518-bd1c-3123e9064f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 3.908582\n",
            "\n",
            "\n",
            "Test Accuracy: 11% (98/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F1BqFW1bOP0Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.Oportunity for improvement\n",
        "\n",
        "We can see that, despite many rounds, the model learns very slowly.\n",
        "\n",
        "We could either run the model for many more epochs, or see what happens if we added more hidden layers in the model architecture.\n",
        "\n",
        "However, probably the smartest thing to do is to test already pre-trained state-of-the-art CNN classifiers and see the results.\n",
        "\n",
        "This is done in the following jupyter notebooks shown on this project. "
      ]
    }
  ]
}
